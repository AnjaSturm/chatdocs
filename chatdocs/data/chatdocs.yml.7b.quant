llm: huggingface
huggingface:
  model: meta-llama/Llama-2-7b-chat-hf
#  device: 0
  model_kwargs:
    use_auth_token: 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
#    load_in_4bit: True
#    bnb_4bit_quant_type: "nf4"
#    bnb_4bit_use_double_quant: True
#    bnb_4bit_compute_dtype: bfloat16
embeddings:
#  model_kwargs:
#    device: cuda
