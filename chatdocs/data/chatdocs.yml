embeddings:
  model: hkunlp/instructor-large
  # model: sentence-transformers/all-MiniLM-L6-v2
  # model_kwargs:
  #   use_auth_token: ${AUTHTOKEN}
  #   device: cuda
  # encode_kwargs:
  #   batch_size: 32
  #   device: 0

llm: huggingface

ctransformers:
  model: TheBloke/Wizard-Vicuna-7B-Uncensored-GGML
  model_file: Wizard-Vicuna-7B-Uncensored.ggmlv3.q4_0.bin
  model_type: llama
  config:
    context_length: 1024

huggingface:
  # model: meta-llama/Llama-2-7b-chat-hf
  # model: meta-llama/Llama-2-13b-chat-hf
  model: jphme/Llama-2-13b-chat-german
  # device: 0
  model_kwargs:
    use_auth_token: ${AUTHTOKEN}
    #device_map: auto
    #load_in_4bit: true
    #load_in_8bit: false
    #quantization_config:
    #load_in_8bit: true
    #load_in_4bit: true
    #bnb_4bit_quant_type: "nf4"
    # bnb_4bit_use_double_quant: true
    #bnb_4bit_compute_dtype: bfloat16
  pipeline_kwargs:
    max_new_tokens: 512

gptq:
  model: TheBloke/Wizard-Vicuna-7B-Uncensored-GPTQ
  model_file: Wizard-Vicuna-7B-Uncensored-GPTQ-4bit-128g.no-act-order.safetensors
  pipeline_kwargs:
    max_new_tokens: 256

download: false

host: 0.0.0.0
port: 5000
auth: false

chroma:
  persist_directory: db
  chroma_db_impl: duckdb+parquet
  anonymized_telemetry: false

retriever:
  search_kwargs:
    k: 4
